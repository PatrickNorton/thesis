@article{AW09,
  author = {Aaronson, Scott and Wigderson, Avi},
  title = {Algebrization: A New Barrier in Complexity Theory},
  year = {2009},
  issue_date = {February 2009},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  volume = {1},
  number = {1},
  issn = {1942-3454},
  doi = {10.1145/1490270.1490272},
  abstract = {Any proof of P ≠ NP will have to overcome two barriers: relativization and natural proofs. Yet over the last decade, we have seen circuit lower bounds (e.g., that PP does not have linear-size circuits) that overcome both barriers simultaneously. So the question arises of whether there is a third barrier to progress on the central questions in complexity theory.In this article, we present such a barrier, which we call algebraic relativization or algebrization. The idea is that, when we relativize some complexity class inclusion, we should give the simulating machine access not only to an oracle A, but also to a low-degree extension of A over a finite field or ring.We systematically go through basic results and open problems in complexity theory to delineate the power of the new algebrization barrier. First, we show that all known nonrelativizing results based on arithmetization---both inclusions such as IP = PSPACE and MIP = NEXP, and separations such as MAEXP ⊄ P/poly---do indeed algebrize. Second, we show that almost all of the major open problems---including P versus NP, P versus RP, and NEXP versus P/poly---will require non-algebrizing techniques. In some cases, algebrization seems to explain exactly why progress stopped where it did: for example, why we have superlinear circuit lower bounds for PromiseMA but not for NP.Our second set of results follows from lower bounds in a new model of algebraic query complexity, which we introduce in this article and which is interesting in its own right. Some of our lower bounds use direct combinatorial and algebraic arguments, while others stem from a surprising connection between our model and communication complexity. Using this connection, we are also able to give an MA-protocol for the Inner Product function with O (√nlogn) communication (essentially matching a lower bound of Klauck), as well as a communication complexity conjecture whose truth would imply NL ≠ NP.},
  journal = {ACM Trans. Comput. Theory},
  month = {2},
  articleno = {2},
  numpages = {54},
  keywords = {query complexity, oracles, interactive proofs, communication complexity, arithmetization, Low-degree polynomials},
  annotate = {An introduction to algebrization and complexity theory.},
}

@book{AB09,
  author = {Arora, Sanjeev and Barak, Boaz},
  title = {Computational Complexity: A Modern Approach},
  year = {2009},
  isbn = {978-0-521-42426-4},
  publisher = {Cambridge University Press},
  address = {USA},
  edition = {1st},
  abstract = {This beginning graduate textbook describes both recent achievements and classical results of computational complexity theory. Requiring essentially no background apart from mathematical maturity, the book can be used as a reference for self-study for anyone interested in complexity, including physicists, mathematicians, and other scientists, as well as a textbook for a variety of courses and seminars. More than 300 exercises are included with a selected hint set.},
  doi = {10.5555/1540612},
}

% https://www.scottaaronson.com/papers/pnp.pdf
@Inbook{Aar16,
  author={Aaronson, Scott},
  editor={Nash, Jr., John Forbes and Rassias, Michael Th.},
  title={{$P \mathop{=}\limits^{?} NP$}},
  bookTitle={Open Problems in Mathematics},
  year={2016},
  publisher={Springer International Publishing},
  address={Cham},
  pages={1--122},
  abstract={In 1950, John Nash sent a remarkable letter to the National Security Agency, in which---seeking to build theoretical foundations for cryptography---he all but formulated what today we call the {\$}{\$}{\backslash}mathsf{\{}P{\}}{\backslash}mathop{\{} ={\}}{\backslash}limits^{\{}?{\}}{\backslash}mathsf{\{}NP{\}}{\$}{\$}problem, and consider one of the great open problems of science. Here I survey the status of this problem in 2016, for a broad audience of mathematicians, scientists, and engineers. I offer a personal perspective on what it's about, why it's important, why it's reasonable to conjecture that P ≠ NP is both true and provable, why proving it is so hard, the landscape of related problems, and crucially, what progress has been made in the last half-century toward solving those problems. The discussion of progress includes diagonalization and circuit lower bounds; the relativization, algebrization, and natural proofs barriers; and the recent works of Ryan Williams and Ketan Mulmuley, which (in different ways) hint at a duality between impossibility proofs and algorithms.},
  isbn={978-3-319-32162-2},
  doi={10.1007/978-3-319-32162-2_1},
  url={https://link.springer.com/chapter/10.1007/978-3-319-32162-2_1},
}

@article{BGS75,
  author = {Baker, Theodore and Gill, John and Solovay, Robert},
  title = {Relativizations of the {$\mathcal{P} \overset{?}{=} \mathcal{NP}$} Question},
  journal = {SIAM Journal on Computing},
  volume = {4},
  number = {4},
  pages = {431-442},
  year = {1975},
  doi = {10.1137/0204037},
  URL = {https://doi.org/10.1137/0204037},
  eprint = {https://doi.org/10.1137/0204037},
  abstract = {We investigate relativized versions of the open question of whether every language accepted nondeterministically in polynomial time can be recognized deterministically in polynomial time. For any set X, let \$\mathcal{P}^X (\text{resp. }\mathcal{NP}^X )\$ be the class of languages accepted in polynomial time by deterministic (resp. nondeterministic) query machines with oracle X. We construct a recursive set A such that \$\mathcal{P}^A = \mathcal{NP}^A \$. On the other hand, we construct a recursive set B such that \$\mathcal{P}^B \ne \mathcal{NP}^B \$. Oracles X are constructed to realize all consistent set inclusion relations between the relativized classes \$\mathcal{P}^X \$, \$\mathcal{NP}^X \$, and co \$\mathcal{NP}^X \$, the family of complements of languages in \$\mathcal{NP}^X \$. Several related open problems are described. }
}

@article{LFKN92,
  author = {Lund, Carsten and Fortnow, Lance and Karloff, Howard and Nisan, Noam},
  title = {Algebraic methods for interactive proof systems},
  year = {1992},
  issue_date = {Oct. 1992},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  volume = {39},
  number = {4},
  issn = {0004-5411},
  url = {https://doi.org/10.1145/146585.146605},
  doi = {10.1145/146585.146605},
  abstract = {A new algebraic technique for the construction of interactive proof systems is presented. Our technique is used to prove that every language in the polynomial-time hierarchy has an interactive proof system. This technique played a pivotal role in the recent proofs that IP = PSPACE [28] and that MIP = NEXP [4].},
  journal = {J. ACM},
  month = oct,
  pages = {859–868},
  numpages = {10},
  keywords = {interactive proof systems}
}

@article{CFGS22,
  author = {Chiesa, Alessandro and Forbes, Michael A. and Gur, Tom and Spooner, Nicholas},
  title = {Spatial Isolation Implies Zero Knowledge Even in a Quantum World},
  year = {2022},
  issue_date = {April 2022},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  volume = {69},
  number = {2},
  issn = {0004-5411},
  url = {https://doi.org/10.1145/3511100},
  doi = {10.1145/3511100},
  abstract = {Zero knowledge plays a central role in cryptography and complexity. The seminal work of Ben-Or et al. (STOC 1988) shows that zero knowledge can be achieved unconditionally for any language in NEXP, as long as one is willing to make a suitable physical assumption: if the provers are spatially isolated, then they can be assumed to be playing independent strategies.Quantum mechanics, however, tells us that this assumption is unrealistic, because spatially-isolated provers could share a quantum entangled state and realize a non-local correlated strategy. The MIP* model captures this setting.In this work, we study the following question: Does spatial isolation still suffice to unconditionally achieve zero knowledge even in the presence of quantum entanglement?We answer this question in the affirmative: we prove that every language in NEXP has a 2-prover zero knowledge interactive proof that is sound against entangled provers; that is, NEXP ⊆ ZK-MIP*.Our proof consists of constructing a zero knowledge interactive probabilistically checkable proof with a strong algebraic structure, and then lifting it to the MIP* model. This lifting relies on a new framework that builds on recent advances in low-degree testing against entangled strategies, and clearly separates classical and quantum tools.Our main technical contribution is the development of new algebraic techniques for obtaining unconditional zero knowledge; this includes a zero knowledge variant of the celebrated sumcheck protocol, a key building block in many probabilistic proof systems. A core component of our sumcheck protocol is a new algebraic commitment scheme, whose analysis relies on algebraic complexity theory.},
  journal = {J. ACM},
  month = {1},
  articleno = {15},
  numpages = {44},
  keywords = {algebraic complexity, sumcheck protocol, interactive PCPs, quantum entangled strategies, multi-prover interactive proofs, Zero knowledge}
}

@book{CLRS,
  title = {Introduction to Algorithms},
  author = {Cormen, Thomas H. and Leiserson, Charles E. and Rivest, Ronald L. and Stein, Clifford},
  edition = {4},
  isbn = {978-0-262-04630-5},
  lccn = {2021037260},
  year = {2022},
  publisher = {MIT Press},
  url = {https://mitpress.mit.edu/9780262046305/introduction-to-algorithms},
}

@book{Sip97,
  author = {Sipser, Michael},
  title = {Introduction to the Theory of Computation},
  year = {1996},
  isbn = {978-0-534-94728-6},
  publisher = {International Thomson Publishing},
  doi = {10.1145/230514.571645},
  edition = {1},
  pagetotal = {396},
}

@article{Sav70,
  title = {Relationships between nondeterministic and deterministic tape complexities},
  journal = {Journal of Computer and System Sciences},
  volume = {4},
  number = {2},
  pages = {177-192},
  year = {1970},
  issn = {0022-0000},
  doi = {10.1016/S0022-0000(70)80006-X},
  url = {https://www.sciencedirect.com/science/article/pii/S002200007080006X},
  author = {Walter J. Savitch},
  abstract = {The amount of storage needed to simulate a nondeterministic tape bounded Turingmachine on a deterministic Turing machine is investigated. Results include the following: Theorem. A nondeterministic L(n)-tape bounded Turing machine can be simulated by a deterministic [L(n)]2-tape bounded Turing machine, provided L(n)≥log2n. Computations of nondeterministic machines are shown to correspond to threadings of certain mazes. This correspondence is used to produce a specific set, namely the set of all codings of threadable mazes, such that, if there is any set which distinguishes nondeterministic tape complexity classes from deterministic tape complexity classes, then this is one such set.}
}

@inproceedings{BFL90,
  author={Babai, L. and Fortnow, L. and Lund, C.},
  booktitle={Proceedings [1990] 31st Annual Symposium on Foundations of Computer Science},
  title={Nondeterministic exponential time has two-prover interactive protocols},
  year={1990},
  volume={},
  number={},
  pages={16-25 vol.1},
  keywords={Protocols;Polynomials;Upper bound;Joining processes;Circuits;Extrapolation;Cryptography;Graphics},
  doi={10.1109/FSCS.1990.89520}
}

@article{JKRS09,
  author = {Juma, Ali and Kabanets, Valentine and Rackoff, Charles and Shpilka, Amir},
  title = {The Black-Box Query Complexity of Polynomial Summation},
  year = {2009},
  issue_date = {April 2009},
  publisher = {Birkhauser Verlag},
  address = {CHE},
  volume = {18},
  number = {1},
  issn = {1016-3328},
  url = {https://doi.org/10.1007/s00037-009-0263-7},
  doi = {10.1007/s00037-009-0263-7},
  journal = {Comput. Complex.},
  month = apr,
  pages = {59–79},
  numpages = {21},
  keywords = {68Q25, 68Q17, 68Q15}
}

@book{Ru76,
  author = {Rudin, Walter},
  title = {Principles of Mathematical Analysis},
  year = {1976},
  publisher = {McGraw-Hill},
  isbn = {978-0-07-085613-4},
  pagetotal = {342},
  edition = {3},
}

@inproceedings{Cook71,
  author = {Cook, Stephen A.},
  title = {The complexity of theorem-proving procedures},
  year = {1971},
  isbn = {9781450374644},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  url = {https://doi.org/10.1145/800157.805047},
  doi = {10.1145/800157.805047},
  abstract = {It is shown that any recognition problem solved by a polynomial time-bounded nondeterministic Turing machine can be “reduced” to the problem of determining whether a given propositional formula is a tautology. Here “reduced” means, roughly speaking, that the first problem can be solved deterministically in polynomial time provided an oracle is available for solving the second. From this notion of reducible, polynomial degrees of difficulty are defined, and it is shown that the problem of determining tautologyhood has the same polynomial degree as the problem of determining whether the first of two given graphs is isomorphic to a subgraph of the second. Other examples are discussed. A method of measuring the complexity of proof procedures for the predicate calculus is introduced and discussed.},
  booktitle = {Proceedings of the Third Annual ACM Symposium on Theory of Computing},
  pages = {151–158},
  numpages = {8},
  location = {Shaker Heights, Ohio, USA},
  series = {STOC '71}
}

@inproceedings{SM73,
  author = {Stockmeyer, L. J. and Meyer, A. R.},
  title = {Word problems requiring exponential time},
  year = {1973},
  isbn = {9781450374309},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  url = {https://doi.org/10.1145/800125.804029},
  doi = {10.1145/800125.804029},
  abstract = {The equivalence problem for Kleene's regular expressions has several effective solutions, all of which are computationally inefficient. In [1], we showed that this inefficiency is an inherent property of the problem by showing that the problem of membership in any arbitrary context-sensitive language was easily reducible to the equivalence problem for regular expressions. We also showed that with a squaring abbreviation ( writing (E)2 for E\texttimes{}E) the equivalence problem for expressions required computing space exponential in the size of the expressions.In this paper we consider a number of similar decidable word problems from automata theory and logic whose inherent computational complexity can be precisely characterized in terms of time or space requirements on deterministic or nondeterministic Turing machines. The definitions of the word problems and a table summarizing their complexity appears in the next section. More detailed comments and an outline of some of the proofs follows in the remaining sections. Complete proofs will appear in the forthcoming papers [9, 10, 13]. In the final section we describe some open problems.},
  booktitle = {Proceedings of the Fifth Annual ACM Symposium on Theory of Computing},
  pages = {1–9},
  numpages = {9},
  location = {Austin, Texas, USA},
  series = {STOC '73}
}

@article{CKS81,
  author = {Chandra, Ashok K. and Kozen, Dexter C. and Stockmeyer, Larry J.},
  title = {Alternation},
  year = {1981},
  issue_date = {Jan. 1981},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  volume = {28},
  number = {1},
  issn = {0004-5411},
  url = {https://dl.acm.org/doi/10.1145/322234.322243},
  doi = {10.1145/322234.322243},
  journal = {J. ACM},
  month = jan,
  pages = {114–133},
  numpages = {20},
}

@inproceedings{MS24,
  author = {Mastel, Kieran and Slofstra, William},
  title = {Two Prover Perfect Zero Knowledge for MIP*},
  year = {2024},
  isbn = {9798400703836},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  url = {https://doi.org/10.1145/3618260.3649702},
  doi = {10.1145/3618260.3649702},
  abstract = {The recent MIP*=RE theorem of Ji, Natarajan, Vidick, Wright, and Yuen shows that the complexity class MIP* of multiprover proof systems with entangled provers contains all recursively enumerable languages. Prior work of Grilo, Slofstra, and Yuen [FOCS '19] further shows (via a technique called simulatable codes) that every language in MIP* has a perfect zero knowledge (PZK) MIP* protocol. The MIP*=RE theorem uses two-prover one-round proof systems, and hence such systems are complete for MIP*. However, the construction in Grilo, Slofstra, and Yuen uses six provers, and there is no obvious way to get perfect zero knowledge with two provers via simulatable codes. This leads to a natural question: are there two-prover PZK-MIP* protocols for all of MIP*? In this paper, we show that every language in MIP* has a two-prover one-round PZK-MIP* protocol, answering the question in the affirmative. For the proof, we use a new method based on a key consequence of the MIP*=RE theorem, which is that every MIP* protocol can be turned into a family of boolean constraint system (BCS) nonlocal games. This makes it possible to work with MIP* protocols as boolean constraint systems, and in particular allows us to use a variant of a construction due to Dwork, Feige, Kilian, Naor, and Safra [Crypto '92] which gives a classical MIP protocol for 3SAT with perfect zero knowledge. To show quantum soundness of this classical construction, we develop a toolkit for analyzing quantum soundness of reductions between BCS games, which we expect to be useful more broadly. This toolkit also applies to commuting operator strategies, and our argument shows that every language with a commuting operator BCS protocol has a two prover PZK commuting operator protocol.},
  booktitle = {Proceedings of the 56th Annual ACM Symposium on Theory of Computing},
  pages = {991–1002},
  numpages = {12},
  keywords = {MIP*, interactive proofs, nonlocal games, perfect zero knowledge},
  location = {Vancouver, BC, Canada},
  series = {STOC 2024},
}

@inproceedings{GOS24,
  author = {Gur, Tom and O'Connor, Jack and Spooner, Nicholas},
  title = {Perfect Zero-Knowledge PCPs for #P},
  year = {2024},
  isbn = {9798400703836},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  url = {https://doi.org/10.1145/3618260.3649698},
  doi = {10.1145/3618260.3649698},
  abstract = {We construct perfect zero-knowledge probabilistically checkable proofs (PZK-PCPs) for every language in #P. This is the first construction of a PZK-PCP for any language outside BPP. Furthermore, unlike previous constructions of (statistical) zero-knowledge PCPs, our construction simultaneously achieves non-adaptivity and zero knowledge against arbitrary (adaptive) polynomial-time malicious verifiers. Our construction consists of a novel masked sumcheck PCP, which uses the combinatorial nullstellen- satz to obtain antisymmetric structure within the hypercube and randomness outside of it. To prove zero knowledge, we introduce the notion of locally simulatable encodings: randomised encodings in which every local view of the encoding can be efficiently sampled given a local view of the message. We show that the code arising from the sumcheck protocol (the Reed–Muller code augmented with subcube sums) admits a locally simulatable encoding. This reduces the algebraic problem of simulating our masked sumcheck to a combinatorial property of antisymmetric functions.},
  booktitle = {Proceedings of the 56th Annual ACM Symposium on Theory of Computing},
  pages = {1724–1730},
  numpages = {7},
  keywords = {Coding Theory, Computational Complexity, Cryptography},
  location = {Vancouver, BC, Canada},
  series = {STOC 2024},
}

@book{APL,
  author = {Iverson, Kenneth E.},
  title = {A Programming Language},
  year = {1962},
  isbn = {978-0471430148},
  publisher = {John Wiley and Sons, Inc.},
  pagetotal = {286},
  url = {https://dl.acm.org/doi/10.5555/1098666},
  edition = {1},
}

@article{Knu92,
 ISSN = {00029890, 19300972},
 URL = {http://www.jstor.org/stable/2325085},
 author = {Donald E. Knuth},
 journal = {The American Mathematical Monthly},
 number = {5},
 pages = {403--422},
 publisher = {[Taylor & Francis, Ltd., Mathematical Association of America]},
 title = {Two Notes on Notation},
 urldate = {2024-11-19},
 volume = {99},
 year = {1992}
}

@Article{Tur36,
  title = {On Computable Numbers, with an Application to the Entscheidungsproblem},
  author = {Turing, A. M.},
  journal = {Proceedings of The London Mathematical Society},
  year = {1936},
  publisher = {Oxford University Press},
  volume = {42},
  pages = {230-265},
  number = {1},
  doi = {10.1112/PLMS/S2-42.1.230},
}

@book{Go01,
  author = {Goldreich, Oded},
  maintitle = {Foundations of Cryptography},
  year = {2001},
  isbn = {978-0-511-54689-1},
  publisher = {Cambridge University Press},
  volume = {1},
  edition = {1},
  pagetotal = {372},
  doi = {10.1017/CBO9780511546891},
}

@article{JNVWY21,
author = {Ji, Zhengfeng and Natarajan, Anand and Vidick, Thomas and Wright, John and Yuen, Henry},
title = {MIP* = RE},
year = {2021},
issue_date = {November 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {64},
number = {11},
issn = {0001-0782},
url = {https://dl.acm.org/doi/10.1145/3485628},
doi = {10.1145/3485628},
abstract = {Note from the Research Highlights Co-Chairs: A Research Highlights paper appearing in Communications is usually peer-reviewed prior to publication. The following paper is unusual in that it is still under review. However, the result has generated enormous excitement in the research community, and came strongly nominated by SIGACT, a nomination seconded by external reviewers.The complexity class NP characterizes the collection of computational problems that have efficiently verifiable solutions. With the goal of classifying computational problems that seem to lie beyond NP, starting in the 1980s complexity theorists have considered extensions of the notion of efficient verification that allow for the use of randomness (the class MA), interaction (the class IP), and the possibility to interact with multiple proofs, or provers (the class MIP). The study of these extensions led to the celebrated PCP theorem and its applications to hardness of approximation and the design of cryptographic protocols.In this work, we study a fourth modification to the notion of efficient verification that originates in the study of quantum entanglement. We prove the surprising result that every problem that is recursively enumerable, including the Halting problem, can be efficiently verified by a classical probabilistic polynomial-time verifier interacting with two all-powerful but noncommunicating provers sharing entanglement. The result resolves long-standing open problems in the foundations of quantum mechanics (Tsirelson's problem) and operator algebras (Connes' embedding problem).},
journal = {Commun. ACM},
month = oct,
pages = {131–138},
numpages = {8}
}
